{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad2ba858-5ec5-47f7-9dcb-1bfcc255011d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/openmmlab-Camp/02-mmpretrain-tutorial/mmpretrain'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('mmpretrain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9fc111f-6a96-4933-9fc4-2842e517a38f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training command is /root/miniconda3/envs/myconda/bin/python /mnt/openmmlab-Camp/02-mmpretrain-tutorial/mmpretrain/mmpretrain/.mim/tools/train.py myconfig/resnet18_finetune.py --launcher none --work-dir=work_dirs. \n",
      "06/06 14:21:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.13 (main, Aug 25 2022, 23:26:10) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 590976619\n",
      "    GPU 0: NVIDIA A16\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 11.3, V11.3.109\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
      "    PyTorch: 1.12.1+cu113\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.3\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.3.2  (built against CUDA 11.5)\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.13.1+cu113\n",
      "    OpenCV: 4.6.0\n",
      "    MMEngine: 0.7.3\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: None\n",
      "    deterministic: False\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "06/06 14:21:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "model = dict(\n",
      "    type='ImageClassifier',\n",
      "    backbone=dict(\n",
      "        type='ResNet',\n",
      "        depth=18,\n",
      "        num_stages=4,\n",
      "        out_indices=(3, ),\n",
      "        style='pytorch'),\n",
      "    neck=dict(type='GlobalAveragePooling'),\n",
      "    head=dict(\n",
      "        type='LinearClsHead',\n",
      "        num_classes=2,\n",
      "        in_channels=512,\n",
      "        loss=dict(type='CrossEntropyLoss', loss_weight=1.0),\n",
      "        topk=(1, 5)),\n",
      "    init_cfg=dict(\n",
      "        type='Pretrained',\n",
      "        checkpoint=\n",
      "        'https://download.openmmlab.com/mmclassification/v0/resnet/resnet18_8xb32_in1k_20210831-fbbb1da6.pth'\n",
      "    ))\n",
      "dataset_type = 'CustomDataset'\n",
      "data_preprocessor = dict(\n",
      "    num_classes=1000,\n",
      "    mean=[123.675, 116.28, 103.53],\n",
      "    std=[58.395, 57.12, 57.375],\n",
      "    to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='RandomResizedCrop', scale=224),\n",
      "    dict(type='RandomFlip', prob=0.5, direction='horizontal'),\n",
      "    dict(type='PackInputs')\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='ResizeEdge', scale=256, edge='short'),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(type='PackInputs')\n",
      "]\n",
      "train_dataloader = dict(\n",
      "    pin_memory=True,\n",
      "    persistent_workers=True,\n",
      "    collate_fn=dict(type='default_collate'),\n",
      "    batch_size=32,\n",
      "    num_workers=5,\n",
      "    dataset=dict(\n",
      "        type='CustomDataset',\n",
      "        data_root='data/cats_dogs_dataset/training_set',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='RandomResizedCrop', scale=224),\n",
      "            dict(type='RandomFlip', prob=0.5, direction='horizontal'),\n",
      "            dict(type='PackInputs')\n",
      "        ]),\n",
      "    sampler=dict(type='DefaultSampler', shuffle=True))\n",
      "val_dataloader = dict(\n",
      "    pin_memory=True,\n",
      "    persistent_workers=True,\n",
      "    collate_fn=dict(type='default_collate'),\n",
      "    batch_size=32,\n",
      "    num_workers=5,\n",
      "    dataset=dict(\n",
      "        type='CustomDataset',\n",
      "        data_root='data/cats_dogs_dataset/val_set',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='ResizeEdge', scale=256, edge='short'),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='PackInputs')\n",
      "        ]),\n",
      "    sampler=dict(type='DefaultSampler', shuffle=False))\n",
      "val_evaluator = dict(type='Accuracy', topk=1)\n",
      "test_dataloader = dict(\n",
      "    pin_memory=True,\n",
      "    persistent_workers=True,\n",
      "    collate_fn=dict(type='default_collate'),\n",
      "    batch_size=32,\n",
      "    num_workers=5,\n",
      "    dataset=dict(\n",
      "        type='CustomDataset',\n",
      "        data_root='data/cats_dogs_dataset/test_set',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='ResizeEdge', scale=256, edge='short'),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='PackInputs')\n",
      "        ]),\n",
      "    sampler=dict(type='DefaultSampler', shuffle=False))\n",
      "test_evaluator = dict(type='Accuracy', topk=1)\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(type='SGD', lr=0.1, momentum=0.9, weight_decay=0.0001))\n",
      "param_scheduler = dict(\n",
      "    type='MultiStepLR', by_epoch=True, milestones=[30, 60, 90], gamma=0.1)\n",
      "train_cfg = dict(by_epoch=True, max_epochs=5, val_interval=1)\n",
      "val_cfg = dict()\n",
      "test_cfg = dict()\n",
      "default_scope = 'mmpretrain'\n",
      "default_hooks = dict(\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    logger=dict(type='LoggerHook', interval=100),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    checkpoint=dict(type='CheckpointHook', interval=1),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    visualization=dict(type='VisualizationHook', enable=False))\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
      "    dist_cfg=dict(backend='nccl'))\n",
      "vis_backends = [dict(type='LocalVisBackend')]\n",
      "visualizer = dict(\n",
      "    type='UniversalVisualizer', vis_backends=[dict(type='LocalVisBackend')])\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume = False\n",
      "randomness = dict(seed=None, deterministic=False)\n",
      "launcher = 'none'\n",
      "work_dir = 'work_dirs'\n",
      "\n",
      "06/06 14:21:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "06/06 14:21:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "/root/miniconda3/envs/myconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "06/06 14:21:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: https://download.openmmlab.com/mmclassification/v0/resnet/resnet18_8xb32_in1k_20210831-fbbb1da6.pth\n",
      "06/06 14:21:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by http backend from path: https://download.openmmlab.com/mmclassification/v0/resnet/resnet18_8xb32_in1k_20210831-fbbb1da6.pth\n",
      "06/06 14:21:24 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for head.fc.weight: copying a param with shape torch.Size([1000, 512]) from checkpoint, the shape in current model is torch.Size([2, 512]).\n",
      "size mismatch for head.fc.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([2]).\n",
      "06/06 14:21:24 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "06/06 14:21:24 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "06/06 14:21:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /mnt/openmmlab-Camp/02-mmpretrain-tutorial/mmpretrain/work_dirs.\n",
      "/root/miniconda3/envs/myconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "06/06 14:21:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][100/201]  lr: 1.0000e-01  eta: 0:02:43  time: 0.1266  data_time: 0.0005  memory: 838  loss: 0.9857\n",
      "06/06 14:21:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][200/201]  lr: 1.0000e-01  eta: 0:02:03  time: 0.1267  data_time: 0.0004  memory: 838  loss: 0.8028\n",
      "06/06 14:21:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: resnet18_finetune_20230606_142116\n",
      "06/06 14:21:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "/root/miniconda3/envs/myconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "06/06 14:22:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][51/51]    accuracy/top1: 49.0319  data_time: 0.0299  time: 0.0681\n",
      "06/06 14:22:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [2][100/201]  lr: 1.0000e-01  eta: 0:01:42  time: 0.1272  data_time: 0.0005  memory: 838  loss: 0.6979\n",
      "06/06 14:22:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [2][200/201]  lr: 1.0000e-01  eta: 0:01:25  time: 0.1272  data_time: 0.0005  memory: 838  loss: 0.6921\n",
      "06/06 14:22:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: resnet18_finetune_20230606_142116\n",
      "06/06 14:22:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 2 epochs\n",
      "06/06 14:22:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [2][51/51]    accuracy/top1: 48.9694  data_time: 0.0108  time: 0.0491\n",
      "06/06 14:22:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [3][100/201]  lr: 1.0000e-01  eta: 0:01:09  time: 0.1275  data_time: 0.0005  memory: 838  loss: 0.6852\n",
      "06/06 14:22:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [3][200/201]  lr: 1.0000e-01  eta: 0:00:55  time: 0.1276  data_time: 0.0004  memory: 838  loss: 0.7179\n",
      "06/06 14:22:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: resnet18_finetune_20230606_142116\n",
      "06/06 14:22:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 3 epochs\n",
      "06/06 14:23:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [3][51/51]    accuracy/top1: 49.9688  data_time: 0.0186  time: 0.0567\n",
      "06/06 14:23:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [4][100/201]  lr: 1.0000e-01  eta: 0:00:40  time: 0.1278  data_time: 0.0005  memory: 838  loss: 0.6897\n",
      "06/06 14:23:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [4][200/201]  lr: 1.0000e-01  eta: 0:00:27  time: 0.1277  data_time: 0.0004  memory: 838  loss: 0.6935\n",
      "06/06 14:23:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: resnet18_finetune_20230606_142116\n",
      "06/06 14:23:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 4 epochs\n",
      "06/06 14:23:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [4][51/51]    accuracy/top1: 53.4666  data_time: 0.0094  time: 0.0480\n",
      "06/06 14:23:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [5][100/201]  lr: 1.0000e-01  eta: 0:00:13  time: 0.1279  data_time: 0.0006  memory: 838  loss: 0.6919\n",
      "06/06 14:23:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: resnet18_finetune_20230606_142116\n",
      "06/06 14:23:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [5][200/201]  lr: 1.0000e-01  eta: 0:00:00  time: 0.1279  data_time: 0.0005  memory: 838  loss: 0.7160\n",
      "06/06 14:23:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: resnet18_finetune_20230606_142116\n",
      "06/06 14:23:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 5 epochs\n",
      "06/06 14:24:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [5][51/51]    accuracy/top1: 53.1543  data_time: 0.0097  time: 0.0482\n",
      "\u001b[32mTraining finished successfully. \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!/root/miniconda3/envs/myconda/bin/mim train mmpretrain myconfig/resnet18_finetune.py --work-dir=work_dirs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
